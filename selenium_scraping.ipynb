{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "\n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "\n",
    "#load the webpage\n",
    "\n",
    "driver.get(\"https://www.redbus.in/online-booking/ksrtc-kerala/?utm_source=rtchometile\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "wait = WebDriverWait(driver, 20)\n",
    "def Kerala_link_route(path):   \n",
    "    LINKS_KERALA=[]\n",
    "    ROUTE_KERALA=[]\n",
    "    # retrive the route links \n",
    "    for i in range(1,6):\n",
    "        paths=driver.find_elements(By.XPATH,path)\n",
    "        \n",
    "        for links in paths:\n",
    "            d = links.get_attribute(\"href\")\n",
    "            LINKS_KERALA.append(d)\n",
    "            \n",
    "        # retrive names of the routes\n",
    "        for route in paths:\n",
    "            ROUTE_KERALA.append(route.text)\n",
    "            \n",
    "        try:\n",
    "            # Wait for the pagination element to be present\n",
    "            pagination = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@class=\"DC_117_paginationTable\"]')))\n",
    "            button = driver.find_element(By.XPATH,f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            #next_button = pagination.find_element(By.XPATH, f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            #time.sleep(3)\n",
    "            #next_button.click()\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {i}\")\n",
    "        break\n",
    "            \n",
    "    return LINKS_KERALA,ROUTE_KERALA\n",
    "\n",
    "LINKS_KERALA,ROUTE_KERALA=Kerala_link_route(\"//a[@class='route']\")\n",
    "\n",
    "kerala=pd.DataFrame({\"Route_name\":ROUTE_KERALA,\"Route_link\":LINKS_KERALA})\n",
    "kerala\n",
    "\n",
    "time.sleep(30)\n",
    "\n",
    "# read the csv file\n",
    "\n",
    "for link in kerala['Route_link']:\n",
    "\n",
    "#retrive the bus details\n",
    " Bus_names_k = []\n",
    " Bus_types_k = []\n",
    " Start_Time_k = []\n",
    " End_Time_k = []\n",
    " Ratings_k = []\n",
    " Total_Duration_k = []\n",
    " Prices_k = []\n",
    " Seats_Available_k = []\n",
    " Route_names_K = []\n",
    " Route_links_K = []\n",
    "\n",
    "for i,r in kerala.iterrows():\n",
    "    link=r[\"Route_link\"]\n",
    "    routes=r[\"Route_name\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # click elements to views bus\n",
    "    try:\n",
    "        clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "        clicks.click()\n",
    "    except:\n",
    "        continue  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    scrolling = True\n",
    "    while scrolling:\n",
    "        old_page_source = driver.page_source\n",
    "        \n",
    "        # Use ActionChains to perform a PAGE_DOWN\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "        \n",
    "        time.sleep(5)  \n",
    "        \n",
    "        new_page_source = driver.page_source\n",
    "        \n",
    "        if new_page_source == old_page_source:\n",
    "            scrolling = False\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_k.append(bus.text)\n",
    "        Route_links_K.append(link)\n",
    "        Route_names_K.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_k.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_k.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_k.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_k.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_k.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_k.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_k.append(seats_elem.text)\n",
    "        \n",
    "print(\"Successfully Completed\")\n",
    "\n",
    "# from list to convert data frame\n",
    "data = {\n",
    "    'Bus_name': Bus_names_k,\n",
    "    'Bus_type': Bus_types_k,\n",
    "    'Start_time': Start_Time_k,\n",
    "    'End_time': End_Time_k,\n",
    "    'Total_duration': Total_Duration_k,\n",
    "    'Price': Prices_k,\n",
    "    \"Seats_Available\":Seats_Available_k,\n",
    "    \"Ratings\":Ratings_k,\n",
    "    'Route_link': Route_links_K,\n",
    "    'Route_name': Route_names_K\n",
    "}\n",
    "\n",
    "Kerala_details = pd.DataFrame(data)\n",
    "#convert dataframe to csv\n",
    "Kerala_path=r\"C:\\jupyter notebook\\redbus.project/kerala_details.csv\"\n",
    "Kerala_details.to_csv(Kerala_path,index=False)\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "\n",
    "driver.get(\"https://www.redbus.in/online-booking/apsrtc/?utm_source=rtchometile\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "wait = WebDriverWait(driver, 40)\n",
    "def Andhra_link_route(path):   \n",
    "    LINKS_Andhra=[]\n",
    "    ROUTE_Andhra=[]\n",
    "    # retrive the route links \n",
    "    for i in range(1,6):\n",
    "        paths=driver.find_elements(By.XPATH,path)\n",
    "        \n",
    "        for links in paths:\n",
    "            d = links.get_attribute(\"href\")\n",
    "            LINKS_Andhra.append(d)\n",
    "            \n",
    "        # retrive names of the routes\n",
    "        for route in paths:\n",
    "            ROUTE_Andhra.append(route.text)\n",
    "            \n",
    "        try:\n",
    "            # Wait for the pagination element to be present\n",
    "            pagination = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@class=\"DC_117_paginationTable\"]')))\n",
    "            button = driver.find_element(By.XPATH,f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            #next_button = pagination.find_element(By.XPATH, f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            #time.sleep(3)\n",
    "            #next_button.click()\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {i}\")\n",
    "        break\n",
    "            \n",
    "    return LINKS_Andhra,ROUTE_Andhra\n",
    "\n",
    "LINKS_Andhra,ROUTE_Andhra=Andhra_link_route(\"//a[@class='route']\")\n",
    "\n",
    "Andhra=pd.DataFrame({\"Route_name\":ROUTE_Andhra,\"Route_link\":LINKS_Andhra})\n",
    "Andhra\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "for link in Andhra['Route_link']:\n",
    "\n",
    "#retrive the bus details\n",
    " Bus_names_A = []\n",
    " Bus_types_A = []\n",
    " Start_Time_A = []\n",
    " End_Time_A = []\n",
    " Ratings_A = []\n",
    " Total_Duration_A = []\n",
    " Prices_A = []\n",
    " Seats_Available_A = []\n",
    " Route_names_A = []\n",
    " Route_links_A = []\n",
    "\n",
    "for i,r in Andhra.iterrows():\n",
    "    link=r[\"Route_link\"]\n",
    "    routes=r[\"Route_name\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # click elements to views bus\n",
    "    try:\n",
    "        clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "        clicks.click()\n",
    "    except:\n",
    "        continue  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    scrolling = True\n",
    "    while scrolling:\n",
    "        old_page_source = driver.page_source\n",
    "        \n",
    "        # Use ActionChains to perform a PAGE_DOWN\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "        \n",
    "        time.sleep(5)  \n",
    "        \n",
    "        new_page_source = driver.page_source\n",
    "        \n",
    "        if new_page_source == old_page_source:\n",
    "            scrolling = False\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_A.append(bus.text)\n",
    "        Route_links_A.append(link)\n",
    "        Route_names_A.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_A.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_A.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_A.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_A.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_A.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_A.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_A.append(seats_elem.text)\n",
    "        \n",
    "print(\"Successfully Completed\")\n",
    "\n",
    "# from list to convert data frame\n",
    "data_A = {\n",
    "    'Bus_name': Bus_names_A,\n",
    "    'Bus_type': Bus_types_A,\n",
    "    'Start_time': Start_Time_A,\n",
    "    'End_time': End_Time_A,\n",
    "    'Total_duration': Total_Duration_A,\n",
    "    'Price': Prices_A,\n",
    "    \"Seats_Available\":Seats_Available_A,\n",
    "    \"Ratings\":Ratings_A,\n",
    "    'Route_link': Route_links_A,\n",
    "    'Route_name': Route_names_A\n",
    "}\n",
    "\n",
    "Andhra_details = pd.DataFrame(data_A)\n",
    "#convert dataframe to csv\n",
    "Andhra_path=r\"C:\\jupyter notebook\\redbus.project/Andhra_details.csv\"\n",
    "Andhra_details.to_csv(Andhra_path,index=False)\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "\n",
    "driver.get(\"https://www.redbus.in/online-booking/tsrtc/?utm_source=rtchometile\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "wait = WebDriverWait(driver, 40)\n",
    "def Telangana_link_route(path):   \n",
    "    LINKS_Telangana=[]\n",
    "    ROUTE_Telangana=[]\n",
    "    # retrive the route links \n",
    "    for i in range(1,6):\n",
    "        paths=driver.find_elements(By.XPATH,path)\n",
    "        \n",
    "        for links in paths:\n",
    "            d = links.get_attribute(\"href\")\n",
    "            LINKS_Telangana.append(d)\n",
    "            \n",
    "        # retrive names of the routes\n",
    "        for route in paths:\n",
    "            ROUTE_Telangana.append(route.text)\n",
    "            \n",
    "        try:\n",
    "            # Wait for the pagination element to be present\n",
    "            pagination = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@class=\"DC_117_paginationTable\"]')))\n",
    "            button = driver.find_element(By.XPATH,f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            #next_button = pagination.find_element(By.XPATH, f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            #time.sleep(3)\n",
    "            #next_button.click()\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {i}\")\n",
    "        break\n",
    "            \n",
    "    return LINKS_Telangana,ROUTE_Telangana\n",
    "\n",
    "LINKS_Telangana,ROUTE_Telangana=Telangana_link_route(\"//a[@class='route']\")\n",
    "\n",
    "Telangana=pd.DataFrame({\"Route_name\":ROUTE_Telangana,\"Route_link\":LINKS_Telangana})\n",
    "Telangana\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "for link in Telangana['Route_link']:\n",
    "\n",
    "#retrive the bus details\n",
    " Bus_names_TE = []\n",
    " Bus_types_TE = []\n",
    " Start_Time_TE = []\n",
    " End_Time_TE = []\n",
    " Ratings_TE = []\n",
    " Total_Duration_TE = []\n",
    " Prices_TE = []\n",
    " Seats_Available_TE = []\n",
    " Route_names_TE = []\n",
    " Route_links_TE = []\n",
    "\n",
    "for i,r in Telangana.iterrows():\n",
    "    link=r[\"Route_link\"]\n",
    "    routes=r[\"Route_name\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # click elements to views bus\n",
    "    try:\n",
    "        clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "        clicks.click()\n",
    "    except:\n",
    "        continue  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    scrolling = True\n",
    "    while scrolling:\n",
    "        old_page_source = driver.page_source\n",
    "        \n",
    "        # Use ActionChains to perform a PAGE_DOWN\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "        \n",
    "        time.sleep(5)  \n",
    "        \n",
    "        new_page_source = driver.page_source\n",
    "        \n",
    "        if new_page_source == old_page_source:\n",
    "            scrolling = False\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_TE.append(bus.text)\n",
    "        Route_links_TE.append(link)\n",
    "        Route_names_TE.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_TE.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_TE.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_TE.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_TE.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_TE.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_TE.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_TE.append(seats_elem.text)\n",
    "        \n",
    "print(\"Successfully Completed\")\n",
    "\n",
    "# from list to convert data frame\n",
    "data_TE = {\n",
    "    'Bus_name': Bus_names_TE,\n",
    "    'Bus_type': Bus_types_TE,\n",
    "    'Start_time': Start_Time_TE,\n",
    "    'End_time': End_Time_TE,\n",
    "    'Total_duration': Total_Duration_TE,\n",
    "    'Price': Prices_TE,\n",
    "    \"Seats_Available\":Seats_Available_TE,\n",
    "    \"Ratings\":Ratings_TE,\n",
    "    'Route_link': Route_links_TE,\n",
    "    'Route_name': Route_names_TE\n",
    "}\n",
    "\n",
    "Telangana_details = pd.DataFrame(data_TE)\n",
    "#convert dataframe to csv\n",
    "TE_path=r\"C:\\jupyter notebook\\redbus.project/Telangana_details.csv\"\n",
    "Telangana_details.to_csv(TE_path,index=False)\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "driver.get(\"https://www.redbus.in/online-booking/west-bengal-transport-corporation?utm_source=rtchometile\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "wait = WebDriverWait(driver, 30)\n",
    "def WB_link_route(path):   \n",
    "    LINKS_WB=[]\n",
    "    ROUTE_WB=[]\n",
    "    # retrive the route links \n",
    "    for i in range(1,6):\n",
    "        paths=driver.find_elements(By.XPATH,path)\n",
    "        \n",
    "        for links in paths:\n",
    "            d = links.get_attribute(\"href\")\n",
    "            LINKS_WB.append(d)\n",
    "            \n",
    "        # retrive names of the routes\n",
    "        for route in paths:\n",
    "            ROUTE_WB.append(route.text)\n",
    "            \n",
    "        try:\n",
    "            # Wait for the pagination element to be present\n",
    "            pagination = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@class=\"DC_117_paginationTable\"]')))\n",
    "            button = driver.find_element(By.XPATH,f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            #next_button = pagination.find_element(By.XPATH, f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            time.sleep(30)\n",
    "            #next_button.click()\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {i}\")\n",
    "        break \n",
    "    return LINKS_WB,ROUTE_WB\n",
    "\n",
    "LINKS_WB,ROUTE_WB=WB_link_route(\"//a[@class='route']\")\n",
    "\n",
    "WB=pd.DataFrame({\"Route_name\":ROUTE_WB,\"Route_link\":LINKS_WB})\n",
    "WB\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "for link in WB['Route_link']:\n",
    "\n",
    "#retrive the bus details\n",
    " Bus_names_WB = []\n",
    " Bus_types_WB = []\n",
    " Start_Time_WB = []\n",
    " End_Time_WB = []\n",
    " Ratings_WB = []\n",
    " Total_Duration_WB = []\n",
    " Prices_WB = []\n",
    " Seats_Available_WB = []\n",
    " Route_names_WB = []\n",
    " Route_links_WB = []\n",
    "\n",
    "for i,r in WB.iterrows():\n",
    "    link=r[\"Route_link\"]\n",
    "    routes=r[\"Route_name\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # click elements to views bus\n",
    "    try:\n",
    "        clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "        clicks.click()\n",
    "    except:\n",
    "        continue  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    scrolling = True\n",
    "    while scrolling:\n",
    "        old_page_source = driver.page_source\n",
    "        \n",
    "        # Use ActionChains to perform a PAGE_DOWN\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "        \n",
    "        time.sleep(5)  \n",
    "        \n",
    "        new_page_source = driver.page_source\n",
    "        \n",
    "        if new_page_source == old_page_source:\n",
    "            scrolling = False\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_WB.append(bus.text)\n",
    "        Route_links_WB.append(link)\n",
    "        Route_names_WB.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_WB.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_WB.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_WB.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_WB.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_WB.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_WB.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_WB.append(seats_elem.text)\n",
    "        \n",
    "print(\"Successfully Completed\")\n",
    "\n",
    "# from list to convert data frame\n",
    "data_WB = {\n",
    "    'Bus_name': Bus_names_WB,\n",
    "    'Bus_type': Bus_types_WB,\n",
    "    'Start_time': Start_Time_WB,\n",
    "    'End_time': End_Time_WB,\n",
    "    'Total_duration': Total_Duration_WB,\n",
    "    'Price': Prices_WB,\n",
    "    \"Seats_Available\":Seats_Available_WB,\n",
    "    \"Ratings\":Ratings_WB,\n",
    "    'Route_link': Route_links_WB,\n",
    "    'Route_name': Route_names_WB\n",
    "}\n",
    "\n",
    "WB_details = pd.DataFrame(data_WB)\n",
    "#convert dataframe to csv\n",
    "WB_path=r\"C:\\jupyter notebook\\redbus.project/WESTBENGAL_details.csv\"\n",
    "WB_details.to_csv(WB_path,index=False)\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "\n",
    "driver.get(\"https://www.redbus.in/online-booking/rsrtc/?utm_source=rtchometile\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "wait = WebDriverWait(driver, 30)\n",
    "def RJ_link_route(path):   \n",
    "    LINKS_RJ=[]\n",
    "    ROUTE_RJ=[]\n",
    "    # retrive the route links \n",
    "    for i in range(1,6):\n",
    "        paths=driver.find_elements(By.XPATH,path)\n",
    "        \n",
    "        for links in paths:\n",
    "            d = links.get_attribute(\"href\")\n",
    "            LINKS_RJ.append(d)\n",
    "            \n",
    "        # retrive names of the routes\n",
    "        for route in paths:\n",
    "            ROUTE_RJ.append(route.text)\n",
    "            \n",
    "        try:\n",
    "            # Wait for the pagination element to be present\n",
    "            pagination = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@class=\"DC_117_paginationTable\"]')))\n",
    "            button = driver.find_element(By.XPATH,f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            #next_button = pagination.find_element(By.XPATH, f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            time.sleep(30)\n",
    "            #next_button.click()\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {i}\")\n",
    "        break \n",
    "    return LINKS_RJ,ROUTE_RJ\n",
    "\n",
    "LINKS_RJ,ROUTE_RJ=RJ_link_route(\"//a[@class='route']\")\n",
    "\n",
    "RJ=pd.DataFrame({\"Route_name\":ROUTE_RJ,\"Route_link\":LINKS_RJ})\n",
    "RJ\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "for link in RJ['Route_link']:\n",
    "\n",
    "#retrive the bus details\n",
    " Bus_names_RJ = []\n",
    " Bus_types_RJ = []\n",
    " Start_Time_RJ = []\n",
    " End_Time_RJ = []\n",
    " Ratings_RJ = []\n",
    " Total_Duration_RJ = []\n",
    " Prices_RJ = []\n",
    " Seats_Available_RJ = []\n",
    " Route_names_RJ = []\n",
    " Route_links_RJ = []\n",
    "\n",
    "for i,r in RJ.iterrows():\n",
    "    link=r[\"Route_link\"]\n",
    "    routes=r[\"Route_name\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # click elements to views bus\n",
    "    try:\n",
    "        clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "        clicks.click()\n",
    "    except:\n",
    "        continue  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    scrolling = True\n",
    "    while scrolling:\n",
    "        old_page_source = driver.page_source\n",
    "        \n",
    "        # Use ActionChains to perform a PAGE_DOWN\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "        \n",
    "        time.sleep(5)  \n",
    "        \n",
    "        new_page_source = driver.page_source\n",
    "        \n",
    "        if new_page_source == old_page_source:\n",
    "            scrolling = False\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_RJ.append(bus.text)\n",
    "        Route_links_RJ.append(link)\n",
    "        Route_names_RJ.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_RJ.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_RJ.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_RJ.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_RJ.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_RJ.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_RJ.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_RJ.append(seats_elem.text)\n",
    "        \n",
    "print(\"Successfully Completed\")\n",
    "\n",
    "# from list to convert data frame\n",
    "data_RJ = {\n",
    "    'Bus_name': Bus_names_RJ,\n",
    "    'Bus_type': Bus_types_RJ,\n",
    "    'Start_time': Start_Time_RJ,\n",
    "    'End_time': End_Time_RJ,\n",
    "    'Total_duration': Total_Duration_RJ,\n",
    "    'Price': Prices_RJ,\n",
    "    \"Seats_Available\":Seats_Available_RJ,\n",
    "    \"Ratings\":Ratings_RJ,\n",
    "    'Route_link': Route_links_RJ,\n",
    "    'Route_name': Route_names_RJ\n",
    "}\n",
    "\n",
    "RJ_details = pd.DataFrame(data_RJ)\n",
    "#convert dataframe to csv\n",
    "RJ_path=r\"C:\\jupyter notebook\\redbus.project/RAJASTHAN_details.csv\"\n",
    "RJ_details.to_csv(RJ_path,index=False)\n",
    "\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "\n",
    "driver.get(\"https://www.redbus.in/online-booking/hrtc/?utm_source=rtchometile\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "wait = WebDriverWait(driver, 30)\n",
    "def HP_link_route(path):   \n",
    "    LINKS_HP=[]\n",
    "    ROUTE_HP=[]\n",
    "    # retrive the route links \n",
    "    for i in range(1,6):\n",
    "        paths=driver.find_elements(By.XPATH,path)\n",
    "        \n",
    "        for links in paths:\n",
    "            d = links.get_attribute(\"href\")\n",
    "            LINKS_HP.append(d)\n",
    "            \n",
    "        # retrive names of the routes\n",
    "        for route in paths:\n",
    "            ROUTE_HP.append(route.text)\n",
    "            \n",
    "        try:\n",
    "            # Wait for the pagination element to be present\n",
    "            pagination = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@class=\"DC_117_paginationTable\"]')))\n",
    "            button = driver.find_element(By.XPATH,f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            #next_button = pagination.find_element(By.XPATH, f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            time.sleep(30)\n",
    "            #next_button.click()\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {i}\")\n",
    "        break \n",
    "    return LINKS_HP,ROUTE_HP\n",
    "\n",
    "LINKS_HP,ROUTE_HP=HP_link_route(\"//a[@class='route']\")\n",
    "\n",
    "HP=pd.DataFrame({\"Route_name\":ROUTE_HP,\"Route_link\":LINKS_HP})\n",
    "HP\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "for link in RJ['Route_link']:\n",
    "\n",
    "#retrive the bus details\n",
    " Bus_names_HP = []\n",
    " Bus_types_HP = []\n",
    " Start_Time_HP = []\n",
    " End_Time_HP = []\n",
    " Ratings_HP = []\n",
    " Total_Duration_HP = []\n",
    " Prices_HP = []\n",
    " Seats_Available_HP = []\n",
    " Route_names_HP = []\n",
    " Route_links_HP = []\n",
    "\n",
    "for i,r in HP.iterrows():\n",
    "    link=r[\"Route_link\"]\n",
    "    routes=r[\"Route_name\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "    # click elements to views bus\n",
    "    try:\n",
    "        clicks = driver.find_element(By.XPATH, \"//div[@class='button']\")\n",
    "        clicks.click()\n",
    "    except:\n",
    "        continue  \n",
    "    time.sleep(2)\n",
    "    \n",
    "    scrolling = True\n",
    "    while scrolling:\n",
    "        old_page_source = driver.page_source\n",
    "        \n",
    "        # Use ActionChains to perform a PAGE_DOWN\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "        \n",
    "        time.sleep(5)  \n",
    "        \n",
    "        new_page_source = driver.page_source\n",
    "        \n",
    "        if new_page_source == old_page_source:\n",
    "            scrolling = False\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_HP.append(bus.text)\n",
    "        Route_links_HP.append(link)\n",
    "        Route_names_HP.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_HP.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_HP.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_HP.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_HP.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_HP.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_HP.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_HP.append(seats_elem.text)\n",
    "        \n",
    "print(\"Successfully Completed\")\n",
    "\n",
    "# from list to convert data frame\n",
    "data_HP = {\n",
    "    'Bus_name': Bus_names_HP,\n",
    "    'Bus_type': Bus_types_HP,\n",
    "    'Start_time': Start_Time_HP,\n",
    "    'End_time': End_Time_HP,\n",
    "    'Total_duration': Total_Duration_HP,\n",
    "    'Price': Prices_HP,\n",
    "    \"Seats_Available\":Seats_Available_HP,\n",
    "    \"Ratings\":Ratings_HP,\n",
    "    'Route_link': Route_links_HP,\n",
    "    'Route_name': Route_names_HP\n",
    "}\n",
    "\n",
    "HP_details = pd.DataFrame(data_HP)\n",
    "#convert dataframe to csv\n",
    "HP_path=r\"C:\\jupyter notebook\\redbus.project\\HIMACHAL_details.csv\"\n",
    "HP_details.to_csv(HP_path,index=False)\n",
    "\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "\n",
    "driver.get(\"https://www.redbus.in/online-booking/astc/?utm_source=rtchometile\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "wait = WebDriverWait(driver, 30)\n",
    "def AS_link_route(path):   \n",
    "    LINKS_AS=[]\n",
    "    ROUTE_AS=[]\n",
    "    # retrive the route links \n",
    "    for i in range(1,6):\n",
    "        paths=driver.find_elements(By.XPATH,path)\n",
    "        \n",
    "        for links in paths:\n",
    "            d = links.get_attribute(\"href\")\n",
    "            LINKS_AS.append(d)\n",
    "            \n",
    "        # retrive names of the routes\n",
    "        for route in paths:\n",
    "            ROUTE_AS.append(route.text)\n",
    "            \n",
    "        try:\n",
    "            # Wait for the pagination element to be present\n",
    "            pagination = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@class=\"DC_117_paginationTable\"]')))\n",
    "            button = driver.find_element(By.XPATH,f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            #next_button = pagination.find_element(By.XPATH, f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            time.sleep(30)\n",
    "            #next_button.click()\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {i}\")\n",
    "        break \n",
    "    return LINKS_AS,ROUTE_AS\n",
    "\n",
    "LINKS_AS,ROUTE_AS=AS_link_route(\"//a[@class='route']\")\n",
    "\n",
    "AS=pd.DataFrame({\"Route_name\":ROUTE_AS,\"Route_link\":LINKS_AS})\n",
    "AS\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "for link in AS['Route_link']:\n",
    "\n",
    "#retrive the bus details\n",
    " Bus_names_AS = []\n",
    " Bus_types_AS = []\n",
    " Start_Time_AS = []\n",
    " End_Time_AS = []\n",
    " Ratings_AS = []\n",
    " Total_Duration_AS = []\n",
    " Prices_AS = []\n",
    " Seats_Available_AS = []\n",
    " Route_names_AS = []\n",
    " Route_links_AS = []\n",
    "\n",
    "for i,r in AS.iterrows():\n",
    "    link=r[\"Route_link\"]\n",
    "    routes=r[\"Route_name\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    scrolling = True\n",
    "    while scrolling:\n",
    "        old_page_source = driver.page_source\n",
    "        \n",
    "        # Use ActionChains to perform a PAGE_DOWN\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "        \n",
    "        time.sleep(5)  \n",
    "        \n",
    "        new_page_source = driver.page_source\n",
    "        \n",
    "        if new_page_source == old_page_source:\n",
    "            scrolling = False\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_AS.append(bus.text)\n",
    "        Route_links_AS.append(link)\n",
    "        Route_names_AS.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_AS.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_AS.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_AS.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_AS.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_AS.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_AS.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_AS.append(seats_elem.text)\n",
    "        \n",
    "print(\"Successfully Completed\")\n",
    "\n",
    "# from list to convert data frame\n",
    "data_AS = {\n",
    "    'Bus_name': Bus_names_AS,\n",
    "    'Bus_type': Bus_types_AS,\n",
    "    'Start_time': Start_Time_AS,\n",
    "    'End_time': End_Time_AS,\n",
    "    'Total_duration': Total_Duration_AS,\n",
    "    'Price': Prices_AS,\n",
    "    \"Seats_Available\":Seats_Available_AS,\n",
    "    \"Ratings\":Ratings_AS,\n",
    "    'Route_link': Route_links_AS,\n",
    "    'Route_name': Route_names_AS\n",
    "}\n",
    "\n",
    "AS_details = pd.DataFrame(data_AS)\n",
    "#convert dataframe to csv\n",
    "AS_path=r\"C:\\jupyter notebook\\redbus.project/ASSAM_details.csv\"\n",
    "AS_details.to_csv(AS_path,index=False)\n",
    "\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "\n",
    "driver.get(\"https://www.redbus.in/online-booking/uttar-pradesh-state-road-transport-corporation-upsrtc/?utm_source=rtchometile\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "wait = WebDriverWait(driver, 30)\n",
    "def UP_link_route(path):   \n",
    "    LINKS_UP=[]\n",
    "    ROUTE_UP=[]\n",
    "    # retrive the route links \n",
    "    for i in range(1,6):\n",
    "        paths=driver.find_elements(By.XPATH,path)\n",
    "        \n",
    "        for links in paths:\n",
    "            d = links.get_attribute(\"href\")\n",
    "            LINKS_UP.append(d)\n",
    "            \n",
    "        # retrive names of the routes\n",
    "        for route in paths:\n",
    "            ROUTE_UP.append(route.text)\n",
    "            \n",
    "        try:\n",
    "            # Wait for the pagination element to be present\n",
    "            pagination = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@class=\"DC_117_paginationTable\"]')))\n",
    "            button = driver.find_element(By.XPATH,f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            #next_button = pagination.find_element(By.XPATH, f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            time.sleep(30)\n",
    "            #next_button.click()\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {i}\")\n",
    "        break \n",
    "    return LINKS_UP,ROUTE_UP\n",
    "\n",
    "LINKS_UP,ROUTE_UP=UP_link_route(\"//a[@class='route']\")\n",
    "\n",
    "UP=pd.DataFrame({\"Route_name\":ROUTE_UP,\"Route_link\":LINKS_UP})\n",
    "UP\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "for link in UP['Route_link']:\n",
    "\n",
    "#retrive the bus details\n",
    " Bus_names_UP = []\n",
    " Bus_types_UP = []\n",
    " Start_Time_UP = []\n",
    " End_Time_UP = []\n",
    " Ratings_UP = []\n",
    " Total_Duration_UP = []\n",
    " Prices_UP = []\n",
    " Seats_Available_UP = []\n",
    " Route_names_UP = []\n",
    " Route_links_UP = []\n",
    "\n",
    "for i,r in UP.iterrows():\n",
    "    link=r[\"Route_link\"]\n",
    "    routes=r[\"Route_name\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    scrolling = True\n",
    "    while scrolling:\n",
    "        old_page_source = driver.page_source\n",
    "        \n",
    "        # Use ActionChains to perform a PAGE_DOWN\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "        \n",
    "        time.sleep(5)  \n",
    "        \n",
    "        new_page_source = driver.page_source\n",
    "        \n",
    "        if new_page_source == old_page_source:\n",
    "            scrolling = False\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_UP.append(bus.text)\n",
    "        Route_links_UP.append(link)\n",
    "        Route_names_UP.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_UP.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_UP.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_UP.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_UP.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_UP.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_UP.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_UP.append(seats_elem.text)\n",
    "        \n",
    "print(\"Successfully Completed\")\n",
    "\n",
    "# from list to convert data frame\n",
    "data_UP = {\n",
    "    'Bus_name': Bus_names_UP,\n",
    "    'Bus_type': Bus_types_UP,\n",
    "    'Start_time': Start_Time_UP,\n",
    "    'End_time': End_Time_UP,\n",
    "    'Total_duration': Total_Duration_UP,\n",
    "    'Price': Prices_UP,\n",
    "    \"Seats_Available\":Seats_Available_UP,\n",
    "    \"Ratings\":Ratings_UP,\n",
    "    'Route_link': Route_links_UP,\n",
    "    'Route_name': Route_names_UP\n",
    "}\n",
    "\n",
    "UP_details = pd.DataFrame(data_UP)\n",
    "#convert dataframe to csv\n",
    "UP_path=r\"C:\\jupyter notebook\\redbus.project/UP_details.csv\"\n",
    "UP_details.to_csv(UP_path,index=False)\n",
    "\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "\n",
    "driver.get(\"https://www.redbus.in/online-booking/bihar-state-road-transport-corporation-bsrtc/?utm_source=rtchometile\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "wait = WebDriverWait(driver, 30)\n",
    "def BH_link_route(path):   \n",
    "    LINKS_BH=[]\n",
    "    ROUTE_BH=[]\n",
    "    # retrive the route links \n",
    "    for i in range(1,6):\n",
    "        paths=driver.find_elements(By.XPATH,path)\n",
    "        \n",
    "        for links in paths:\n",
    "            d = links.get_attribute(\"href\")\n",
    "            LINKS_BH.append(d)\n",
    "            \n",
    "        # retrive names of the routes\n",
    "        for route in paths:\n",
    "            ROUTE_BH.append(route.text)\n",
    "            \n",
    "        try:\n",
    "            # Wait for the pagination element to be present\n",
    "            pagination = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@class=\"DC_117_paginationTable\"]')))\n",
    "            button = driver.find_element(By.XPATH,f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            #next_button = pagination.find_element(By.XPATH, f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            time.sleep(30)\n",
    "            #next_button.click()\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {i}\")\n",
    "        break \n",
    "    return LINKS_BH,ROUTE_BH\n",
    "\n",
    "LINKS_BH,ROUTE_BH=BH_link_route(\"//a[@class='route']\")\n",
    "\n",
    "BH=pd.DataFrame({\"Route_name\":ROUTE_BH,\"Route_link\":LINKS_BH})\n",
    "BH\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "for link in BH['Route_link']:\n",
    "\n",
    "#retrive the bus details\n",
    " Bus_names_BH = []\n",
    " Bus_types_BH = []\n",
    " Start_Time_BH = []\n",
    " End_Time_BH = []\n",
    " Ratings_BH = []\n",
    " Total_Duration_BH = []\n",
    " Prices_BH = []\n",
    " Seats_Available_BH = []\n",
    " Route_names_BH = []\n",
    " Route_links_BH = []\n",
    "\n",
    "for i,r in BH.iterrows():\n",
    "    link=r[\"Route_link\"]\n",
    "    routes=r[\"Route_name\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    scrolling = True\n",
    "    while scrolling:\n",
    "        old_page_source = driver.page_source\n",
    "        \n",
    "        # Use ActionChains to perform a PAGE_DOWN\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "        \n",
    "        time.sleep(5)  \n",
    "        \n",
    "        new_page_source = driver.page_source\n",
    "        \n",
    "        if new_page_source == old_page_source:\n",
    "            scrolling = False\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_BH.append(bus.text)\n",
    "        Route_links_BH.append(link)\n",
    "        Route_names_BH.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_BH.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_BH.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_BH.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_BH.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_BH.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_BH.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_BH.append(seats_elem.text)\n",
    "        \n",
    "print(\"Successfully Completed\")\n",
    "\n",
    "# from list to convert data frame\n",
    "data_BH = {\n",
    "    'Bus_name': Bus_names_BH,\n",
    "    'Bus_type': Bus_types_BH,\n",
    "    'Start_time': Start_Time_BH,\n",
    "    'End_time': End_Time_BH,\n",
    "    'Total_duration': Total_Duration_BH,\n",
    "    'Price': Prices_BH,\n",
    "    \"Seats_Available\":Seats_Available_BH,\n",
    "    \"Ratings\":Ratings_BH,\n",
    "    'Route_link': Route_links_BH,\n",
    "    'Route_name': Route_names_BH\n",
    "}\n",
    "\n",
    "BH_details = pd.DataFrame(data_BH)\n",
    "#convert dataframe to csv\n",
    "BH_path=r\"C:\\jupyter notebook\\redbus.project/Bihar_details.csv\"\n",
    "BH_details.to_csv(BH_path,index=False)\n",
    "\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "\n",
    "driver.get(\"https://www.redbus.in/online-booking/jksrtc\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "wait = WebDriverWait(driver, 30)\n",
    "def JK_link_route(path):   \n",
    "    LINKS_JK=[]\n",
    "    ROUTE_JK=[]\n",
    "    # retrive the route links \n",
    "    for i in range(1,6):\n",
    "        paths=driver.find_elements(By.XPATH,path)\n",
    "        \n",
    "        for links in paths:\n",
    "            d = links.get_attribute(\"href\")\n",
    "            LINKS_JK.append(d)\n",
    "            \n",
    "        # retrive names of the routes\n",
    "        for route in paths:\n",
    "            ROUTE_JK.append(route.text)\n",
    "            \n",
    "        try:\n",
    "            # Wait for the pagination element to be present\n",
    "            pagination = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@class=\"DC_117_paginationTable\"]')))\n",
    "            button = driver.find_element(By.XPATH,f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            #next_button = pagination.find_element(By.XPATH, f'//div[@class=\"DC_117_pageTabs \" and text()={i+1}]')\n",
    "            time.sleep(30)\n",
    "            #next_button.click()\n",
    "        except NoSuchElementException:\n",
    "            print(f\"No more pages to paginate at step {i}\")\n",
    "        break \n",
    "    return LINKS_JK,ROUTE_JK\n",
    "\n",
    "LINKS_JK,ROUTE_JK=JK_link_route(\"//a[@class='route']\")\n",
    "\n",
    "JK=pd.DataFrame({\"Route_name\":ROUTE_JK,\"Route_link\":LINKS_JK})\n",
    "JK\n",
    "\n",
    "\n",
    "time.sleep(15)\n",
    "\n",
    "for link in JK['Route_link']:\n",
    "\n",
    "#retrive the bus details\n",
    " Bus_names_JK = []\n",
    " Bus_types_JK = []\n",
    " Start_Time_JK = []\n",
    " End_Time_JK = []\n",
    " Ratings_JK = []\n",
    " Total_Duration_JK = []\n",
    " Prices_JK = []\n",
    " Seats_Available_JK = []\n",
    " Route_names_JK = []\n",
    " Route_links_JK = []\n",
    "\n",
    "for i,r in JK.iterrows():\n",
    "    link=r[\"Route_link\"]\n",
    "    routes=r[\"Route_name\"]\n",
    "\n",
    "# Loop through each link\n",
    "    driver.get(link)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Click on elements to reveal bus details\n",
    "    elements = driver.find_elements(By.XPATH, f\"//a[contains(@href, '{link}')]\")\n",
    "    for element in elements:\n",
    "        element.click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    scrolling = True\n",
    "    while scrolling:\n",
    "        old_page_source = driver.page_source\n",
    "        \n",
    "        # Use ActionChains to perform a PAGE_DOWN\n",
    "        ActionChains(driver).send_keys(Keys.PAGE_DOWN).perform()\n",
    "        \n",
    "        time.sleep(5)  \n",
    "        \n",
    "        new_page_source = driver.page_source\n",
    "        \n",
    "        if new_page_source == old_page_source:\n",
    "            scrolling = False\n",
    "\n",
    "    # Extract bus details\n",
    "    bus_name = driver.find_elements(By.XPATH, \"//div[@class='travels lh-24 f-bold d-color']\")\n",
    "    bus_type = driver.find_elements(By.XPATH, \"//div[@class='bus-type f-12 m-top-16 l-color evBus']\")\n",
    "    start_time = driver.find_elements(By.XPATH, \"//*[@class='dp-time f-19 d-color f-bold']\")\n",
    "    end_time = driver.find_elements(By.XPATH, \"//*[@class='bp-time f-19 d-color disp-Inline']\")\n",
    "    total_duration = driver.find_elements(By.XPATH, \"//*[@class='dur l-color lh-24']\")\n",
    "    try:\n",
    "        rating = driver.find_elements(By.XPATH,\"//div[@class='clearfix row-one']/div[@class='column-six p-right-10 w-10 fl']\")\n",
    "    except:\n",
    "        continue\n",
    "    price = driver.find_elements(By.XPATH, '//*[@class=\"fare d-block\"]')\n",
    "    seats = driver.find_elements(By.XPATH, \"//div[contains(@class, 'seat-left')]\")\n",
    "\n",
    "    # Append data to respective lists\n",
    "    for bus in bus_name:\n",
    "        Bus_names_JK.append(bus.text)\n",
    "        Route_links_JK.append(link)\n",
    "        Route_names_JK.append(routes)\n",
    "    for bus_type_elem in bus_type:\n",
    "        Bus_types_JK.append(bus_type_elem.text)\n",
    "    for start_time_elem in start_time:\n",
    "        Start_Time_JK.append(start_time_elem.text)\n",
    "    for end_time_elem in end_time:\n",
    "        End_Time_JK.append(end_time_elem.text)\n",
    "    for total_duration_elem in total_duration:\n",
    "        Total_Duration_JK.append(total_duration_elem.text)\n",
    "    for ratings in rating:\n",
    "        Ratings_JK.append(ratings.text)\n",
    "    for price_elem in price:\n",
    "        Prices_JK.append(price_elem.text)\n",
    "    for seats_elem in seats:\n",
    "        Seats_Available_JK.append(seats_elem.text)\n",
    "        \n",
    "print(\"Successfully Completed\")\n",
    "\n",
    "# from list to convert data frame\n",
    "data_JK = {\n",
    "    'Bus_name': Bus_names_JK,\n",
    "    'Bus_type': Bus_types_JK,\n",
    "    'Start_time': Start_Time_JK,\n",
    "    'End_time': End_Time_JK,\n",
    "    'Total_duration': Total_Duration_JK,\n",
    "    'Price': Prices_JK,\n",
    "    \"Seats_Available\":Seats_Available_JK,\n",
    "    \"Ratings\":Ratings_JK,\n",
    "    'Route_link': Route_links_JK,\n",
    "    'Route_name': Route_names_JK\n",
    "}\n",
    "\n",
    "JK_details = pd.DataFrame(data_JK)\n",
    "#convert dataframe to csv\n",
    "JK_path=r\"C:\\jupyter notebook\\redbus.project/J&K_details.csv\"\n",
    "JK_details.to_csv(JK_path,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
